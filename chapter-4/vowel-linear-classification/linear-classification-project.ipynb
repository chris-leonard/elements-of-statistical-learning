{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Optimisation\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# To partition data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For validation and parameter runing\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to get experience applying the methods from Chapter 4.\n",
    "\n",
    "Things I would like to try:\n",
    "- Linear regression of indicator matrix\n",
    "- Linear discriminant analysis\n",
    "    - LDA but choosing cut-point to minimise training error (validation?)\n",
    "    - Comparing QDA with LDA on quadratic terms\n",
    "    - Regularised LDA (validation)\n",
    "    - Projection onto canonical variates\n",
    "    - Reduced-Rank LDA (validation)\n",
    "- Logistic Regression\n",
    "    - Hypothesis testing using Z-scores\n",
    "    - Subset selection using Wald Test, Likelihood Ratio Test, or Rao's Score Test\n",
    "    - $L^1$-regularised Logistic Regression (validation)\n",
    "- Separating hyperplanes? Presumably won't actually be possible\n",
    "\n",
    "Some of these would work better on binary classification problems (such as spam data) and some would work better on classification problems with more than two classes (such as vowel data). I could always do a mixture but that wouldn't allow me to compare performance on test data.\n",
    "\n",
    "The logistic regression hypothesis tests have only been described for binary classification problems. The disadvantage of the vowel data is that there aren't very many data points. A downside with binary classification is that a lot of these techniques become very similar.\n",
    "\n",
    "I will move forward with vowel data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same dataset as in the enclosing folder. To get a better split in the data I have recombined it and split it into training, validation, and test sets in the proportion 60-20-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>-3.725</td>\n",
       "      <td>1.904</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>0.433</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>1.047</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.425</td>\n",
       "      <td>-0.678</td>\n",
       "      <td>-0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>-2.967</td>\n",
       "      <td>2.781</td>\n",
       "      <td>-1.277</td>\n",
       "      <td>0.354</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>1.505</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>-4.175</td>\n",
       "      <td>3.320</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>0.988</td>\n",
       "      <td>-1.480</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-3.194</td>\n",
       "      <td>1.589</td>\n",
       "      <td>-0.774</td>\n",
       "      <td>0.814</td>\n",
       "      <td>-1.087</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.218</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.030</td>\n",
       "      <td>1.764</td>\n",
       "      <td>-0.386</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      10\n",
       "0  11 -3.725  1.904 -0.737  0.433 -0.369  1.047  0.120  0.425 -0.678 -0.391\n",
       "1   5 -2.967  2.781 -1.277  0.354 -0.936  1.505 -0.004 -0.418 -0.560  0.725\n",
       "2   8 -4.175  3.320 -0.446  0.988 -1.480  0.133  0.507  0.605  0.691 -0.462\n",
       "3   4 -3.194  1.589 -0.774  0.814 -1.087  0.618  0.218 -0.450 -0.003  0.526\n",
       "4   4 -2.030  1.764 -0.386 -0.249  0.180  0.117  0.096 -0.121  0.067 -0.552"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "train = pd.read_csv('vowel-train.csv', header=None)\n",
    "val = pd.read_csv('vowel-val.csv', header=None)\n",
    "test = pd.read_csv('vowel-test.csv', header=None)\n",
    "\n",
    "# Combine the training/validation set into a single dataframe\n",
    "trainval = pd.concat([train, val]).reset_index(drop = True)\n",
    "\n",
    "# Take a look at the data\n",
    "trainval.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>792.0</td>\n",
       "      <td>6.039141</td>\n",
       "      <td>3.180175</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>11.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>792.0</td>\n",
       "      <td>-3.220919</td>\n",
       "      <td>0.866414</td>\n",
       "      <td>-5.211</td>\n",
       "      <td>-3.90375</td>\n",
       "      <td>-3.1710</td>\n",
       "      <td>-2.62650</td>\n",
       "      <td>-0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>792.0</td>\n",
       "      <td>1.897836</td>\n",
       "      <td>1.176604</td>\n",
       "      <td>-1.274</td>\n",
       "      <td>1.07050</td>\n",
       "      <td>1.9070</td>\n",
       "      <td>2.78550</td>\n",
       "      <td>5.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>792.0</td>\n",
       "      <td>-0.529126</td>\n",
       "      <td>0.706045</td>\n",
       "      <td>-2.487</td>\n",
       "      <td>-0.99925</td>\n",
       "      <td>-0.5860</td>\n",
       "      <td>-0.10225</td>\n",
       "      <td>1.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>792.0</td>\n",
       "      <td>0.530307</td>\n",
       "      <td>0.743921</td>\n",
       "      <td>-1.247</td>\n",
       "      <td>-0.04725</td>\n",
       "      <td>0.4675</td>\n",
       "      <td>1.09850</td>\n",
       "      <td>2.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>792.0</td>\n",
       "      <td>-0.306451</td>\n",
       "      <td>0.676090</td>\n",
       "      <td>-2.127</td>\n",
       "      <td>-0.79400</td>\n",
       "      <td>-0.3120</td>\n",
       "      <td>0.17625</td>\n",
       "      <td>1.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>792.0</td>\n",
       "      <td>0.641318</td>\n",
       "      <td>0.592950</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>0.22975</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>1.02250</td>\n",
       "      <td>2.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>792.0</td>\n",
       "      <td>-0.005274</td>\n",
       "      <td>0.449826</td>\n",
       "      <td>-1.454</td>\n",
       "      <td>-0.31225</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.28275</td>\n",
       "      <td>1.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>792.0</td>\n",
       "      <td>0.333104</td>\n",
       "      <td>0.578171</td>\n",
       "      <td>-1.293</td>\n",
       "      <td>-0.10575</td>\n",
       "      <td>0.3220</td>\n",
       "      <td>0.77325</td>\n",
       "      <td>1.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>792.0</td>\n",
       "      <td>-0.308096</td>\n",
       "      <td>0.568027</td>\n",
       "      <td>-1.613</td>\n",
       "      <td>-0.70800</td>\n",
       "      <td>-0.3005</td>\n",
       "      <td>0.09125</td>\n",
       "      <td>1.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>792.0</td>\n",
       "      <td>-0.068176</td>\n",
       "      <td>0.603858</td>\n",
       "      <td>-1.680</td>\n",
       "      <td>-0.54550</td>\n",
       "      <td>-0.1450</td>\n",
       "      <td>0.37225</td>\n",
       "      <td>1.294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count      mean       std    min      25%     50%      75%     max\n",
       "0   792.0  6.039141  3.180175  1.000  3.00000  6.0000  9.00000  11.000\n",
       "1   792.0 -3.220919  0.866414 -5.211 -3.90375 -3.1710 -2.62650  -0.961\n",
       "2   792.0  1.897836  1.176604 -1.274  1.07050  1.9070  2.78550   5.074\n",
       "3   792.0 -0.529126  0.706045 -2.487 -0.99925 -0.5860 -0.10225   1.431\n",
       "4   792.0  0.530307  0.743921 -1.247 -0.04725  0.4675  1.09850   2.377\n",
       "5   792.0 -0.306451  0.676090 -2.127 -0.79400 -0.3120  0.17625   1.831\n",
       "6   792.0  0.641318  0.592950 -0.836  0.22975  0.5625  1.02250   2.327\n",
       "7   792.0 -0.005274  0.449826 -1.454 -0.31225  0.0330  0.28275   1.286\n",
       "8   792.0  0.333104  0.578171 -1.293 -0.10575  0.3220  0.77325   1.972\n",
       "9   792.0 -0.308096  0.568027 -1.613 -0.70800 -0.3005  0.09125   1.309\n",
       "10  792.0 -0.068176  0.603858 -1.680 -0.54550 -0.1450  0.37225   1.294"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display descriptive statistics\n",
    "trainval.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594 training samples\n",
      "198 validation samples\n",
      "198 test samples\n",
      "10 features\n",
      "Class labels:  [ 1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "# Print values\n",
    "print('{} training samples'.format(train.shape[0]))\n",
    "print('{} validation samples'.format(val.shape[0]))\n",
    "print('{} test samples'.format(test.shape[0]))\n",
    "print('{} features'.format(train.shape[1] - 1))\n",
    "\n",
    "# Classes\n",
    "print('Class labels: ', np.sort(train.iloc[:, 0].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be more convenient if our class labels were 0,..,10 so I'll just subtract 1 from the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel classes by subtracting one\n",
    "train.iloc[:, 0] = train.iloc[:, 0] - 1\n",
    "trainval.iloc[:, 0] = trainval.iloc[:, 0] - 1\n",
    "val.iloc[:, 0] = val.iloc[:, 0] - 1\n",
    "test.iloc[:, 0] = test.iloc[:, 0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     72\n",
       "1     67\n",
       "2     77\n",
       "3     71\n",
       "4     75\n",
       "5     65\n",
       "6     69\n",
       "7     73\n",
       "8     74\n",
       "9     75\n",
       "10    74\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Occurances of different classes in training/validation data\n",
    "class_counts = trainval.iloc[:, 0].value_counts()\n",
    "class_counts[list(range(K))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So different classes occur in approximately equal proportion. This means that the base error rate (from classifying to the most common class) is around $1 - \\frac{1}{K}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base error rate: 0.9091\n"
     ]
    }
   ],
   "source": [
    "print('Base error rate: {:.4f}'.format(1 - 1/11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare the data for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into inputs and outputs\n",
    "y_train = train.iloc[:, 0].to_numpy()\n",
    "X_train = train.iloc[:, 1:].to_numpy()\n",
    "N_train = len(y_train)\n",
    "\n",
    "y_trainval = trainval.iloc[:, 0].to_numpy()\n",
    "X_trainval = trainval.iloc[:, 1:].to_numpy()\n",
    "N_trainval = len(y_trainval)\n",
    "\n",
    "y_val = val.iloc[:, 0].to_numpy()\n",
    "X_val = val.iloc[:, 1:].to_numpy()\n",
    "N_val = len(y_val)\n",
    "\n",
    "y_test = test.iloc[:, 0].to_numpy()\n",
    "X_test = test.iloc[:, 1:].to_numpy()\n",
    "N_test = len(y_test)\n",
    "\n",
    "# Some useful constants\n",
    "p = X_train.shape[1]\n",
    "K = len(np.unique(y_train))\n",
    "\n",
    "# Predefined split to aid validation with sklearn\n",
    "test_fold = [-1] * N_train + [0] * N_val\n",
    "ps = PredefinedSplit(test_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression of Indicator Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by simply performing ordinary least squares regression on the indicator matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_indicator_responses(y, K):\n",
    "    'Turn output vector with entries 0,..,K-1 into indicator reponse matrix'\n",
    "    N = y.shape[0]\n",
    "\n",
    "    Y = np.zeros(shape=(N, K))\n",
    "    Y[range(N), y] = 1\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicator response matrices\n",
    "Y_train = gen_indicator_responses(y_train, K)\n",
    "Y_trainval = gen_indicator_responses(y_trainval, K)\n",
    "#Y_val = gen_indicator_responses(y_val, K)\n",
    "#Y_test = gen_indicator_responses(y_test, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use training and validation to get an estimate of prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinary least squares training error: 0.540\n",
      "Ordinary least squares validation error: 0.591\n"
     ]
    }
   ],
   "source": [
    "# Fit regression model to training and validation data\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train, Y_train)\n",
    "\n",
    "# Generate classification predictions for training data\n",
    "y_train_pred_ols = ols.predict(X_train)\n",
    "y_train_pred_ols = np.argmax(y_train_pred_ols, axis=1)\n",
    "train_err_ols = 1 - accuracy_score(y_train, y_train_pred_ols)\n",
    "print('Ordinary least squares training error: {:.3f}'.format(train_err_ols))\n",
    "\n",
    "# Classification predictions for validation data\n",
    "y_val_pred_ols = ols.predict(X_val)\n",
    "y_val_pred_ols = np.argmax(y_val_pred_ols, axis=1)\n",
    "val_err_ols = 1 - accuracy_score(y_val, y_val_pred_ols)\n",
    "print('Ordinary least squares validation error: {:.3f}'.format(val_err_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with standard linear discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear discriminant analysis training error: 0.315\n",
      "Linear discriminant analysis validation error: 0.409\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Training error\n",
    "y_train_pred_lda = lda.predict(X_train)\n",
    "train_err_lda = 1 - accuracy_score(y_train, y_train_pred_lda)\n",
    "print('Linear discriminant analysis training error: {:.3f}'.format(train_err_lda))\n",
    "\n",
    "# Validation error\n",
    "y_val_pred_lda = lda.predict(X_val)\n",
    "val_err_lda = 1 - accuracy_score(y_val, y_val_pred_lda)\n",
    "print('Linear discriminant analysis validation error: {:.3f}'.format(val_err_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTF suggest setting the cut-point to minimise misclassification error over the training data.\n",
    "\n",
    "Optimising this isn't working at the moment.\n",
    "\n",
    "**Tomorrow**:\n",
    "- Fix this\n",
    "- Think about when I want to be using just training data and when I want to use training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7861952861952862\n"
     ]
    }
   ],
   "source": [
    "intercept = np.zeros(shape=K)\n",
    "y_pred = np.argmax(intercept + X_train @ lda.coef_.T, axis=1)\n",
    "err = 1 - accuracy_score(y_train, y_pred)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminant(intercept, gradient, y):\n",
    "    intercept = np.append(intercept, 0)\n",
    "    y_pred = np.argmax(intercept + gradient, axis=1)\n",
    "    err = 1 - accuracy_score(y, y_pred)\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40909090909090906"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminant(x0, gradient, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = [lda.intercept_[i] - lda.intercept_[K-1] for i in range(K-1)]\n",
    "gradient = X_val @ lda.coef_.T\n",
    "y = y_val\n",
    "\n",
    "res = minimize(discriminant, x0=x0, args=(gradient, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 0.40909090909090906\n",
       " hess_inv: array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
       "      jac: array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 12\n",
       "      nit: 0\n",
       "     njev: 1\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ -6.0295333 ,   1.35236471,  12.34263333,  16.32726963,\n",
       "         4.36711261,   9.36933876,  -2.53462038, -26.1909396 ,\n",
       "       -19.85781028, -26.60995777])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-6.029533296027886,\n",
       " 1.3523647123435274,\n",
       " 12.34263332893547,\n",
       " 16.327269631518224,\n",
       " 4.367112606697166,\n",
       " 9.36933875805241,\n",
       " -2.5346203799362574,\n",
       " -26.190939600022908,\n",
       " -19.85781028463713,\n",
       " -26.609957765278388]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
