{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Fit a Gaussian model for each class and find misclassification rate on test data.\n",
    "\n",
    "Need:\n",
    "- Functions to estimate $\\hat{\\pi}_k$, $\\hat{\\mu}_k$, and $\\hat{\\Sigma}_k$ for each class $k$\n",
    "- Functions to compute quadratic descriminant functions $\\delta_k(x)$ for a given $x$ (or a whole dataset $\\mathbf{X})$)\n",
    "- Function to classify an $x$ or a dataset $\\mathbf{X}$ using then $\\delta_k(x)$\n",
    "- Function to calculate misclassification rate given estimates $\\hat{y}$ and real values $y$\n",
    "- Function to convert classes to integers 0,..,K-1 and record in dictionary\n",
    "- Function to convert $y$ to response matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_class_codes(y):\n",
    "    '''\n",
    "    Code distinct entries of y as 0,..,K-1. Ordered with floats/ints\n",
    "    first followed by strings.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y: Numpy array of size (N, ) consisting of K distinct class labels\n",
    "       Entries must be floats of strings\n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    code_to_class: dict with keys 0,..,K-1 and values class labels\n",
    "    \n",
    "    class_to_code: dict with class labels as keys and values 0,..,K-1\n",
    "                   Inverse of code_to_class\n",
    "    '''\n",
    "    # Get ordered class lables\n",
    "    sorted_values = np.sort(np.unique(y))\n",
    "    \n",
    "    # Generate dictionaries\n",
    "    code_to_class = dict(enumerate(sorted_values))\n",
    "    class_to_code = {v:k for k, v in code_to_class.items()}\n",
    "    \n",
    "    return code_to_class, class_to_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_classes(y, class_to_code):\n",
    "    '''\n",
    "    Replace class labels with codes\n",
    "    '''\n",
    "    return np.array([class_to_code[i] for i in y])\n",
    "\n",
    "def decode_classes(y, code_to_class):\n",
    "    '''\n",
    "    Replace codes with class labels\n",
    "    '''\n",
    "    return np.array([code_to_class[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_indicator_responses(y):\n",
    "    '''\n",
    "    Turn output vector with entries 0,..,K-1 into\n",
    "    indicator reponse matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y: Numpy array of shape (N,) with entries 0,..,K-1\n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    Y: Numpy array of shape (N, K)\n",
    "       1s in position [i, y[i]], 0s elsewhere\n",
    "    '''\n",
    "    N = y.shape[0]\n",
    "    \n",
    "    Y = np.zeros(shape=(N, K))\n",
    "    Y[range(N), y] = 1\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_params(X, Y):\n",
    "    '''\n",
    "    Estimate prior probabilities, class means, and class variances\n",
    "    for quadratic discriminant analysis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: Numpy array of shape (N, p) containing input data\n",
    "    \n",
    "    Y: Numpy array of shape (N, K), indicator response matrix\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    prior_prob: Numpy array of shape (K, )\n",
    "                Estimates of prior probabilities of each class\n",
    "                \n",
    "    sample_means: Numpy array of shape (K, p)\n",
    "                  kth row is sample mean of class k\n",
    "    \n",
    "    sample_vars: Numpy array of shape (K, p, p)\n",
    "                 kth entry is sample covariance matrix of class k\n",
    "    '''\n",
    "    N, p = X.shape\n",
    "    _, K = Y.shape\n",
    "    \n",
    "    prior_prob = np.sum(Y, axis=0) / np.sum(Y)\n",
    "    \n",
    "    sample_means = np.empty(shape=(K, p))\n",
    "    sample_vars = np.empty(shape=(K, p, p))\n",
    "    \n",
    "    for k in range(K):\n",
    "        class_inputs = X[Y[:, k] == 1, :]\n",
    "        \n",
    "        sample_means[k] = np.mean(class_inputs, axis = 0)\n",
    "        \n",
    "        sample_vars[k] = (class_inputs - sample_means[k]).T @ (class_inputs - sample_means[k])\n",
    "        sample_vars[k] /= class_inputs.shape[0] - K\n",
    "        \n",
    "    return prior_prob, sample_means, sample_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminant_func(X, prior_prob, sample_means, sample_vars):\n",
    "    '''\n",
    "    Apply all quadratic discriminant functions to input data X.\n",
    "    In practice last 3 parameters are estimated using est_params\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: Numpy array of shape (N, p) consisting of input data\n",
    "    \n",
    "    prior_prob: Numpy array of shape (K, )\n",
    "                Prior probabilities for each class\n",
    "    \n",
    "    class_means: Numpy array of shape (K, p)\n",
    "                 kth row is population mean of class k\n",
    "    \n",
    "    class_vars: Numpy array of shape (K, p, p)\n",
    "                kth entry is covariance matrix of class k\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    delta: Numpy array of shape (N, K)\n",
    "           ith row gives K discriminant funcs applied to ith data point\n",
    "    \n",
    "    '''\n",
    "    # Get eigendecomposition of each covariance matrix\n",
    "    eval, evect = np.linalg.eigh(class_vars)\n",
    "    \n",
    "    # Calculate D^(-1/2) for each set of evalues\n",
    "    diag = np.apply_along_axis(np.diag, axis=1, arr=np.sqrt(1/eval))\n",
    "    \n",
    "    # Initialise K copies of data to apply K disc func\n",
    "    delta = np.array([X] * K)\n",
    "    \n",
    "    # Calculate Mahalanobis distance for each class\n",
    "    delta = delta - class_means[:, np.newaxis, :]    \n",
    "    delta = delta @ evect @ diag    \n",
    "    delta = np.sum(delta**2, axis=2).T\n",
    "    \n",
    "    # Add constant terms\n",
    "    delta = prior_prob - delta / 2 - np.sum(np.log(eval), axis=1) / 2\n",
    "\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X, prior_prob, sample_means, sample_vars):\n",
    "    '''\n",
    "    Classify each data point in X\n",
    "    In practice last 3 parameters are estimated using est_params\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: Numpy array of shape (N, p) consisting of input data\n",
    "    \n",
    "    prior_prob: Numpy array of shape (K, )\n",
    "                Prior probabilities for each class\n",
    "    \n",
    "    class_means: Numpy array of shape (K, p)\n",
    "                 kth row is population mean of class k\n",
    "    \n",
    "    class_vars: Numpy array of shape (K, p, p)\n",
    "                kth entry is covariance matrix of class k\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    y_est: Numpy array of shape (N, ) with entries in range(K)\n",
    "           ith entry gives estimated class for ith input\n",
    "    '''\n",
    "    # Apply discriminant functions\n",
    "    delta = discriminant_func(X)\n",
    "    \n",
    "    y_est = np.argmax(delta, axis=1)\n",
    "    \n",
    "    return y_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_error(y, y_est):\n",
    "    '''\n",
    "    Returns classification error in estimating y by y_est\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y: Numpy array of shape (N,) with entries 0,..,K-1\n",
    "       True class outputs\n",
    "       \n",
    "    y_est: Numpy array of shape (N,) with entries 0,..,K-1\n",
    "           Estimated class outputs\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    err: Float between 0 and 1\n",
    "         Number of misclassified data points over total number\n",
    "    '''\n",
    "    N = y.shape[0]\n",
    "    err = np.sum((y != y_est).astype(int)) / N\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should test this by generating some multivariate Gaussian data and using this to estimate the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([\n",
    "    0, 0, 0, 1, 1, 1\n",
    "])\n",
    "\n",
    "Y = np.array([\n",
    "    [1, 0],\n",
    "    [1, 0],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    [0, 1]\n",
    "])\n",
    "\n",
    "X = np.array([\n",
    "    [3, 0],\n",
    "    [2, 1],\n",
    "    [1, 1],\n",
    "    [1, 1],\n",
    "    [1, 2],\n",
    "    [0, 3]\n",
    "])\n",
    "\n",
    "N, p = X.shape\n",
    "_, K = Y.shape\n",
    "\n",
    "prior_prob, sample_means, sample_vars = est_params(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: Function for quadratic discriminant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "sample_mean = sample_means[k]\n",
    "sample_var = sample_vars[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval, evect = np.linalg.eigh(sample_vars[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval, evect = np.linalg.eigh(sample_var)\n",
    "\n",
    "delta = (X - sample_mean) @ evect @ np.diag(np.sqrt(1/eval))\n",
    "delta = np.sum(delta**2, axis=1)\n",
    "delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do this for all $k$ simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.        , 0.66666667],\n",
       "       [0.66666667, 2.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval, evect = np.linalg.eigh(sample_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3, 0],\n",
       "        [2, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [0, 3]],\n",
       "\n",
       "       [[3, 0],\n",
       "        [2, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [0, 3]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([X] * K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.        , -1.        ],\n",
       "        [-1.        ,  0.66666667]],\n",
       "\n",
       "       [[ 0.66666667, -1.        ],\n",
       "        [-1.        ,  2.        ]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.47185793, -0.8816746 ],\n",
       "        [-0.8816746 ,  0.47185793]],\n",
       "\n",
       "       [[-0.8816746 , -0.47185793],\n",
       "        [-0.47185793,  0.8816746 ]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [0, 2]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.apply_along_axis(np.diag, axis=1, arr=np.array([[0, 1], [1, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.13148291, 0.        ],\n",
       "        [0.        , 2.53518376]],\n",
       "\n",
       "       [[0.13148291, 0.        ],\n",
       "        [0.        , 2.53518376]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.apply_along_axis(np.diag, axis=1, arr=eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.        ,  1.10940039],\n",
       "        [-1.        , -0.46225016]],\n",
       "\n",
       "       [[-0.46225016, -1.        ],\n",
       "        [ 1.10940039,  2.        ]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evect @ np.apply_along_axis(np.diag, axis=1, arr=eval) @ evect.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply QD functions to each row of X\n",
    "eval, evect = np.linalg.eigh(sample_vars)\n",
    "diag = np.apply_along_axis(np.diag, axis=1, arr=np.sqrt(1/eval))\n",
    "\n",
    "delta = np.array([X] * K)\n",
    "delta = delta - sample_means[:, np.newaxis, :]\n",
    "delta = delta @ evect @ diag\n",
    "delta = np.sum(delta**2, axis=2)\n",
    "delta = delta.T# kth row is delta_k(X)\n",
    "\n",
    "delta = prior_prob - delta / 2 - np.sum(np.log(eval), axis=1) / 2\n",
    "\n",
    "# Classify data points\n",
    "y_est = np.argmax(delta, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_est = np.zeros(shape=(len(y_est), K))\n",
    "Y_est[range(len(y_est)), y_est] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_est[range(len(y_est)), y_est] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_est = gen_indicator_responses(y_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 1., -1.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y - Y_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((y != y_est).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_error(y, y_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
