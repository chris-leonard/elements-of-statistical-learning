{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413ced8e",
   "metadata": {},
   "source": [
    "# Chapter 8 Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c32cb9",
   "metadata": {},
   "source": [
    "## 8.2 The Bootstrap and Maximum Likelihood Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f9125d",
   "metadata": {},
   "source": [
    "### 8.2.1 A Smoothing Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1efbe8c",
   "metadata": {},
   "source": [
    "Suppose that we have one dimensional data $\\mathbb{Z}=\\lbrace z_1, \\ldots, z_N\\rbrace$ where $z_i=(x_i, y_i)$.\n",
    "We might fit a curve to this using cubic splines with knots at quantiles of the $x$-values.\n",
    "Since this is just a linear model we can generate (pointwise) confidence bands around our estimate (see ยง3.2 for details)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8a022a",
   "metadata": {},
   "source": [
    "We can also generate confidence bands using bootstrapping.\n",
    "We consider two different versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2dbc05",
   "metadata": {},
   "source": [
    "**Non-parametric bootstrap:**\n",
    "Draw bootstrap samples with replacement from the $z_i$.\n",
    "For each boostrap sample fit a cubic spline to the data.\n",
    "Generate a confidence interval at each $x$ by taking percentiles of bootstrap splines evaluated at the point.\n",
    "\n",
    "*Note:* There is a decision here whether to use the original knots or generate new knots using the bootstrapped $x$-values.\n",
    "This choice depends on whether we want to capture the variability from the position of the knots as well as the noise in the targets.\n",
    "The flexibility of the method means that we could even use more complex methods for choosing the number and position of the knots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd2393",
   "metadata": {},
   "source": [
    "**Parametric boostrap:**\n",
    "Fit cubic splines to the original training data and then simulate new responses by adding Gaussian noise to the predicted values.\n",
    "That is, if $\\mu(x)$ is our spline function, sample $y_i^* \\sim \\mathcal{N}(\\mu(x_i), \\hat{\\sigma}^2)$, where $\\hat{\\sigma}$ is the sample variance of the $y_i$. We then construct our boostrapped splines by fitting to the new $(x_i, y_i^*)$. Again, we can construct pointwise confidence intervals by taking percentiles of the bootstrapped splines.\n",
    "\n",
    "In this case, the confidence intervals agree with those generated through the least squares estimate at the start.\n",
    "In general the parametric boostrap agrees with maximum likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff9763",
   "metadata": {},
   "source": [
    "### 8.2.2 Maximum Likelihood Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8cb162",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "If we specify a parametric model for $Z$ via a probability density function $z \\sim g_{\\theta}(z)$ then we can calculate the maximum likelihood estimator $\\hat{\\theta}$ for the parameters $\\theta$.\n",
    "The sampling distribution of the MLE has a limiting Normal distribution:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{\\theta} \\longrightarrow \\mathcal{N}\\left( \\theta_0, \\mathbf{i}(\\theta_0)^{-1}\\right),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{i}(\\theta)$ is the Fisher information and $\\theta_0$ is the true parameter value.\n",
    "Using $\\hat{\\theta}$ to approximate $\\hat{theta}_0$, this allows us to construct approximate confidence intervals around the MLE, which we can then use to get pointwise confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784a8d99",
   "metadata": {},
   "source": [
    "## 8.3 Bayesian Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b96c374",
   "metadata": {},
   "source": [
    "We can alternatively generate Bayesian credible intervals by putting priors on the spline coefficients (and variance).\n",
    "The text shows that if the spline coefficients are uncorrelated in prior, then the Bayesian intervals approach the parametric boostrap and maximum likelihood as the variance of the priors increase; that is, as they tend towards a non-informative prior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31554311",
   "metadata": {},
   "source": [
    "## 8.4 Relationship Between the Bootstrap and Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef27850a",
   "metadata": {},
   "source": [
    "They show that for a Bernoulli sample with $\\alpha$ successes and $\\beta$ failures, the Bayesian posterior $\\text{Beta}(\\alpha, \\beta)$ that results from an  uninformative prior is almost the same as the boostrap distribution of the estimator for the true success probability.\n",
    "This generalises to a Multinomial distribution using the Dirichlet distribution instead of the Beta distribution.\n",
    "\n",
    "In this sense the bootstrap distribution represents an approximate non-parametric, uninformative posterior distribution for our parameter.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
